# Sim2Real

All Models are wrong, some are useful.

## 市场格局
### 类比
* 模拟器游戏(Kingdom come, No man sky, Kenshi, Mount & Blade, etc):
    * 玩法交互性、游戏性较弱，更加注重“模拟”而非“游玩”。
    * 通常使用老旧的自研引擎, 而非更先进更好用的商业引擎，这是大量工作量壁垒导致的。
    * 地图可扩展，可自动生成，几乎场景内的一切逻辑、物体，都经过数据化。
    * 人物AI行为通常并非其他游戏的“有限状态机”，而是更加数据驱动的“行为树”，甚至引入一些激进的新技术，如PPO强化学习等。
    * 动画可能并非设计师手K，而是生成、算法模拟，因此行为可能奇怪，但符合游戏世界观的“逻辑”。
    * 引擎通常内置一套 Reflection -> Component&System 编程架构，编辑器、地图机制等设计爷与这一类模拟性质“玩法”高度耦合，并在此基础上有了数年的工作。

* Unity3D & Unreal：
    * 200x - 201x年，大团队上大量使用自研引擎，个体开发者与小团队无法独立开发游戏。
    * 缺少资产市场，缺少开源社区，不同领域（美术、策划、程序）之间无法共享工作。
    * Unity 3.x 开始，Asset Store提供稳定的校验、测试、发售平台，保证大多数用户“买下来就能用”，出现BUG后可以责令开发者修复或退款。
    * Unity 4.x 开始，基于C# .Net的脚本编程系统逐渐强大，降低编程门槛。
    * UE4 提供蓝图 + C++的编程模式，同样降低开发门槛并保证上限。
    * 用户：需要资产有Store，需要开发有蓝图、脚本，因此获得市场欢迎。
    * 总体来说gameplay程序员理解的sim有两大工作：
        * 控制 - vehicle sim physics-animation
        * 模拟 - rigidbody cloth destruction fluid
    * 大部分gp程序员的工作范畴在控制部分，也即通过简单逻辑触发单次映射。sim的control则更倾向于通过抽出具体场景问题，然后通过数值或非数值方式对问题进行求解以解决一类问题。

* 为什么商业游戏引擎一直很难盈利？
    * 游戏作为To C产品，终端对容错率要求苛刻（千分之一崩溃率可能导致大量差评）。
    * 用户硬件与平台千奇百怪（PC, Console, Mobile, etc），对于通用引擎而言极其难以兼容.
    * 为解决 corner case，引入大量 work around，带来大量历史包袱。
    * 任何一点老技术的迭代，和新技术的引入，都可能导致引擎稳定性骤降、口碑崩坏。
    * 技术选型为了“让用户能容易学习”而非“满足游戏项目需求”，是商业性质导致的，在游戏开发领域尤其严重。
        * 如Nanite，Lumen，Streaming Level等，功能大而全，小缺陷却极多，在大项目中导致人力空转，但小规模开发很容易出结果。
    * 新技术同样很难插件化，暴露接口 -> 接触平台特性 -> 在另一些平台可能无法运行 -> 市场不满意。
    * 技术日渐落后于学界，团队则需要投入更大成本重构(UE4 -> UE5)或转型(Unity)。
    * Epic团队更加注重引擎的社区属性而非盈利性，让社区做“免费测试”，帮助完善引擎并用于开发游戏，如Fortnite等。

* 具身虚拟引擎
    * 市场混沌初级，目前缺乏可用的产品。
    * Genesis未来可期，All in Pythonic是否是一条正确道路仍未可知，笔者目前持保留态度。
    * 大多如Issac-Sim，提供了简单的ROS接口，不可拔插的渲染物理算法。很难完成 Bench。Traning 等任务。
    * 用户直接使用游戏引擎 + 插件，缺乏专业工具。
    * 远端部署、多计算后端并发部署等工作接近空白。
    * 大多数仍然是传统的硬编码或OOP的架构、距离数据驱动遥远，这对于各种训练并不友好。
    * 大量布局World Model工作，使用推理而非模拟，将物理世界的规律诉诸隐表达，这是一条未知的道路。
    * 有了大量虚拟训练的新鲜且合理的概念，未来可期。

## 抽象理念
* 竞争力是什么？独特在哪里？
    * 提供强大的UI，包括API，Editor GUI等，这是团队多年工程经验所能保证的。
    * 提供可编程流水线框架与流程（下文）。
    * 有强大的渲染模拟算法作为中坚力量，有高性能计算库等技术积累作为基底，保证默认强大的同时自身可扩展性高。
* 接近模拟器游戏，同时具身领域对逻辑控制性要求不高，对模拟质量，渲染质量，和场景数据化程度要求更高，有可多后端部署、可复现、计算无偏、可并发等要求。
* 用户通常可以使用更高级、更统一的硬件，这使得模块化、插件化成为可能，更适合去中心化的社区型开发环境。
* 也需要第一方团队提供一套高质量的基本流程，做到场景、交互逻辑、几何、动画、渲染，全流程独立可用。
* 需要Shell script + embedded script，前者帮助用户从外部当库调用，后者帮助用户在内部使用脚本，方便热更等。
* 场景表达类似“回合制游戏”，一切数据和被数据驱动的事件的变动、更新，以timeline作为唯一标准变化。这样的设计保证了理论上在任何机器下以同样的时间输入时，都应当输出相同的结果。将一个演示看做一个“纯函数”。
* “可视化”是最重要的理念之一，必须保证几乎所有的功能都做到“可视化”，并不仅限于渲染或表现，如风场、磁场、温度、湿度等，均需要提供可编程的可视化方法。
* UI很重要，但花哨的Embedded GUI并非重要，Editor主体应当处于DCC中，而本体则提供简单GUI或headless mode。
* 虽然花哨的Editor GUI 是一个卖点，作为宣传使用，但更需要的是几乎不需要编程就可以拥有的GUI，比如基于反射的IMGUI。
* 帮助厂家定制硬件，获取硬件数据，完善平台。
* “大自然是不可控的”，Controlling 是一个与 Simulation 相矛盾的方向。更多Controlling意味着引入更多ad-hoc，则无法保证自然性。在设计UI时需要
* Validation流程，对于社区插件或功能，需要完善测试验证流程。
* 一个训练流程可复现，就可以作为完整的解决方案被推广、出售、购买。
    * 如一个抓娃娃机器的流程：虚拟训练+强化学习，成功抓到 -> 进行实际测试，发现无法正确识别娃娃 -> 是否是引擎中娃娃材质贴图太过单一导致过拟合？是否是CV模型不收敛？ -> 改进流程，成功识别 -> 抓取失败滑落 -> 摩擦力参数填写错误？ -> 抓取成功，方案完成。
    * 以上整套方案可复现可扩展，甚至每一步都可以切分后作为单独步骤修改（这是数据驱动的编程范式所保证的），这套方案便有了竞争力。
    * 这意味着资产与脚本代码实质性分离，同上例，识别娃娃是一个level，执行抓取是另一个level，前者通过data pipeline传递抓取位置，需要抓取物大致体积等。data pipeline是通用的，可以跨设备，跨硬件。


## 技术选型
* 整个工程由：物理、渲染、本地ML、网络、Editor GUI、场景管理、脚本绑定等模块，以插件模块的形式组成，除了有强依赖以外（如物理渲染依赖场景），每一个组件默认支持可拆分。
* Host使用C++, Python，Lua等语言运行时，GPU Device使用Luisa Compute提供的跨平台支持，默认可以做到Windows, Linux, MacOS上编译、运行。
    * 业务方面，讲究适合的系统做适合的事情。
    * Windows提供稳定的实时gpu计算与渲染平台(dx12, vulkan等)，优先提供前端实时编辑服务。
    * Linux则注重后端计算(llvm, cuda等)，优先提供远端部署服务。
    * Mac用户通常聚焦于轻量办公，远程工作，优先提供云服务到win, linux等系统。
* 渲染自研路径追踪渲染器，使用光谱渲染，支持衍射光栅等高级材质，理论可用于不可见光渲染，支持实时预览，大场景，离线高精度。
* 物理模拟使用Lib-UIPC作为基底，离线无穿透物理计算，保证高精度无偏仿真。实时可提供AVBD等先进实时物理算法做预览等
* 本地ML考虑基于CUDA等后端的libtorch、onnx-api等部署，通过Luisa Compute提供的interop插件完成与其他组件的无缝互联.
* Editor GUI使用IMGUI，配合脚本可以做到自动生成，方便二次开发。
* 网络部分，结合游戏引擎的开发经验，搭建云连接。API调用等工作，等同于脚本绑定。（下文）
* 由C++等原生语言提供接口，Clang预处理反射，生成脚本绑定代码，做到默认多语言支持。LuisaCompute同样提供了pybind，与Taichi，Warp等相仿。
